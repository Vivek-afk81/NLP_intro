{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvBj1gns+4ELXk8nJLfQ+y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vivek-afk81/NLP_intro/blob/main/nlp_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5Y-EiQs5SeR",
        "outputId": "8181a358-10b8-429b-ec90-e58e2ca3fddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "except ImportError:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/nlp\")"
      ],
      "metadata": {
        "id": "0xDA6Nj37Bz7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NLP Phase 1: Text Cleaning & Normalization\n",
        "\n",
        "Machine learning models cannot understand raw text.\n",
        "We must clean, normalize, and structure text before converting it into numbers."
      ],
      "metadata": {
        "id": "hHe35KOS-gZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 1 :- Load the text data"
      ],
      "metadata": {
        "id": "YTKW9RrD-4Z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"this is a classic Anaconda environment mismatch problem\"\n",
        "text=text.lower()\n",
        "\n",
        "print(\"Lower text: \",text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRGEwTOU6gBX",
        "outputId": "0c1325e2-7a45-439c-cf5a-5e9579132b3b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lower text:  this is a classic anaconda environment mismatch problem\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###step 2 :-Remove Punctuations\n",
        "we we will remove everything except letters and spaces\n",
        "Using re- regular expression"
      ],
      "metadata": {
        "id": "rOQnNuQK7Y1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text =re.sub(r'[^\\w\\s]','',text)\n",
        "print(\"Without punctuation: \",text)\n",
        "\n",
        "## Removes everything except word characters and whitespace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm811YU46txP",
        "outputId": "5af47740-8bf2-4ab6-a930-f4c6f925b22d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without punctuation:  this is a classic anaconda environment mismatch problem\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###STEP 3 :- TOKENIZATION"
      ],
      "metadata": {
        "id": "7z9nrcBz8wpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This is whitespace tokenization\n",
        "tokens=text.split()\n",
        "print(\"tokens\",tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s1BK_5X8ii_",
        "outputId": "c7d7c21a-f4ef-4389-b62d-04e633a83008"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens ['this', 'is', 'a', 'classic', 'anaconda', 'environment', 'mismatch', 'problem']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###STEP 4 :- Remove Stop Words"
      ],
      "metadata": {
        "id": "Z2pGv6xx9EpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#remove stop words is am are the etc\n",
        "\n",
        "stopwords = [\n",
        "    \"a\", \"an\", \"the\",\n",
        "    \"is\", \"am\", \"are\", \"was\", \"were\",\n",
        "    \"this\", \"that\", \"these\", \"those\",\n",
        "    \"and\", \"or\", \"but\",\n",
        "    \"to\", \"of\", \"in\", \"on\"\n",
        "]\n",
        "# filtered_tokens=[]\n",
        "# for word in tokens:\n",
        "#   if word not in stopwords:\n",
        "#     filtered_tokens.append(word)\n",
        "\n",
        "filtered_tokens=[words for words in tokens if words not in stopwords]\n",
        "\n",
        "print(filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GaC_UCu9AMH",
        "outputId": "5746dee0-3080-4cf3-81ec-ce08fbe2f94e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['classic', 'anaconda', 'environment', 'mismatch', 'problem']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 5 :- Simple Stemming (Demonstration)"
      ],
      "metadata": {
        "id": "nNR33A5pB9Sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This is not a full stemmer like Porter Stemmer.\n",
        "#It only demonstrates the idea of reducing words to a base form\n",
        "def simple_stem(word):\n",
        "  if word.endswith(\"ing\"):\n",
        "    return word[:-3]\n",
        "  return word\n",
        "\n",
        "stemmed_words=[]\n",
        "for word in filtered_tokens:\n",
        "  stemmed_words.append(simple_stem(word))\n",
        "\n",
        "print(\"After stemming :\",stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNnSsv3Q-Gpk",
        "outputId": "686980f6-da72-4018-c034-ef3352d5ab6e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After stemming : ['classic', 'anaconda', 'environment', 'mismatch', 'problem']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NLP Phase 2 -Words to vector\n",
        "\n",
        "Why ML - because ML only understands numbers\n",
        "\n",
        "Machine learning models work with numerical features, not text.\n",
        "\n"
      ],
      "metadata": {
        "id": "v9dBG35j_ezQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer #converting text to count\n"
      ],
      "metadata": {
        "id": "cJCNFcDz_Ywm"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Bag of Words (Count Vectorization)\n",
        "\n",
        "Each document is represented as a vector of word counts."
      ],
      "metadata": {
        "id": "_Fh3t8W9AycS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"This is a classic problem in programming.\",\n",
        "    \"Anaconda environment mismatch can cause import errors.\",\n",
        "    \"Python libraries must be installed in the correct environment.\",\n",
        "    \"Understanding environments saves a lot of debugging time.\"\n",
        "]\n",
        "# Vectorize\n",
        "vectorizer=CountVectorizer()\n",
        "X=vectorizer.fit_transform(sentences) # learn the vocubalary and covert the sentences to numbers"
      ],
      "metadata": {
        "id": "NN9wR2tH_Dfh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COKUsmvOCChl",
        "outputId": "09e54a1c-e64f-44a7-aed4-be783db79dc1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
              "\twith 29 stored elements and shape (4, 27)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"vocubalary\")\n",
        "print(vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFzNbwk_AuqK",
        "outputId": "268de921-30eb-4a82-a713-06ef9f65ea01"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocubalary\n",
            "['anaconda' 'be' 'can' 'cause' 'classic' 'correct' 'debugging'\n",
            " 'environment' 'environments' 'errors' 'import' 'in' 'installed' 'is'\n",
            " 'libraries' 'lot' 'mismatch' 'must' 'of' 'problem' 'programming' 'python'\n",
            " 'saves' 'the' 'this' 'time' 'understanding']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nBag of Words Matrix:\\n\")\n",
        "print(X.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zrvcyv5A4-J",
        "outputId": "fb2f73e2-e777-4f22-8691-6b66ae3260f0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bag of Words Matrix:\n",
            "\n",
            "[[0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0]\n",
            " [1 0 1 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here:\n",
        "- each row = sentence\n",
        "- each column = word\n",
        "- each value=count"
      ],
      "metadata": {
        "id": "9wH5YoRRBkfD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Another Example (Different Corpus)"
      ],
      "metadata": {
        "id": "dmqnrBKFBOGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    \"Speech recognition requires the correct audio drivers.\",\n",
        "    \"Missing dependencies often lead to runtime errors.\",\n",
        "    \"Virtual environments help isolate Python projects.\",\n",
        "    \"Proper setup makes development smoother.\"\n",
        "]\n",
        "vectorizer=CountVectorizer()\n",
        "X=vectorizer.fit_transform(sentences)\n",
        "print(\"Vocabulary\",vectorizer.get_feature_names_out())\n",
        "print(\"\\nMatrix : \")\n",
        "print(X.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEr5m354Bg8C",
        "outputId": "b451b169-1737-4a6e-b2c6-7c62fa6513bf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary ['audio' 'correct' 'dependencies' 'development' 'drivers' 'environments'\n",
            " 'errors' 'help' 'isolate' 'lead' 'makes' 'missing' 'often' 'projects'\n",
            " 'proper' 'python' 'recognition' 'requires' 'runtime' 'setup' 'smoother'\n",
            " 'speech' 'the' 'to' 'virtual']\n",
            "\n",
            "Matrix : \n",
            "[[1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0]\n",
            " [0 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Introducing TF-IDF\n",
        "###TERM FREQUENCY - INVERSE DOCUMENT FREQUENCY\n",
        "\n",
        "TF-IDF Vectorization\n",
        "\n",
        "Bag of Words treats all words equally.\n",
        "TF-IDF assigns lower weight to common words and higher weight to important words.\n",
        "\n",
        "TF-IDF = TF Ã— IDF\n",
        "\n",
        "TF  = term frequency in a document  \n",
        "IDF = log(total documents / documents containing the term)\n",
        "\n"
      ],
      "metadata": {
        "id": "Z-Iquy8wHiXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer=TfidfVectorizer()\n",
        "X=vectorizer.fit_transform(sentences)\n",
        "# Internally it will:\n",
        "#calculate TF\n",
        "# Multiple tf X idf\n",
        "#generate matrix\n",
        "#"
      ],
      "metadata": {
        "id": "45vVjSzxHAIQ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vocabulary\",vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkLrUcgUIr7C",
        "outputId": "e5b2d070-becd-4829-ada4-722487126809"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary ['audio' 'correct' 'dependencies' 'development' 'drivers' 'environments'\n",
            " 'errors' 'help' 'isolate' 'lead' 'makes' 'missing' 'often' 'projects'\n",
            " 'proper' 'python' 'recognition' 'requires' 'runtime' 'setup' 'smoother'\n",
            " 'speech' 'the' 'to' 'virtual']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TF-IDF Matrix: \")\n",
        "print(X.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tew0KKHVJCHW",
        "outputId": "b14fac1f-9f0d-46d6-8579-758608915038"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Matrix: \n",
            "[[0.37796447 0.37796447 0.         0.         0.37796447 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.37796447 0.37796447\n",
            "  0.         0.         0.         0.37796447 0.37796447 0.\n",
            "  0.        ]\n",
            " [0.         0.         0.37796447 0.         0.         0.\n",
            "  0.37796447 0.         0.         0.37796447 0.         0.37796447\n",
            "  0.37796447 0.         0.         0.         0.         0.\n",
            "  0.37796447 0.         0.         0.         0.         0.37796447\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.40824829\n",
            "  0.         0.40824829 0.40824829 0.         0.         0.\n",
            "  0.         0.40824829 0.         0.40824829 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.40824829]\n",
            " [0.         0.         0.         0.4472136  0.         0.\n",
            "  0.         0.         0.         0.         0.4472136  0.\n",
            "  0.         0.         0.4472136  0.         0.         0.\n",
            "  0.         0.4472136  0.4472136  0.         0.         0.\n",
            "  0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IDF calculation:\n",
        "#log(total documents / documents containing word)"
      ],
      "metadata": {
        "id": "hws_wTPgJ1nt"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n2oCK_3wCll3"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}